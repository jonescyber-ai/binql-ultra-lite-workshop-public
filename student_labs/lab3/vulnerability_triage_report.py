"""
Lab 3.4: Vulnerability Triage Report Module.

This module uses LLM to synthesize findings from Labs 3.1-3.3 into comprehensive
vulnerability triage reports with executive summaries, risk assessments, and
actionable recommendations.

The module integrates with previous labs:
- Lab 3.1: User-controlled input sources (user_input_detection.py)
- Lab 3.2: Source-to-sink paths (source_to_sink_analysis.py)
- Lab 3.3: Ranked path risk analysis (complexity_analysis.py)

Students implement 5 functions:
1. collect_lab3_findings() - Gather findings from Labs 3.1, 3.2, 3.3
2. format_findings_for_llm() - Format findings into LLM prompt
3. generate_executive_summary() - LLM-generated executive summary
4. generate_vulnerability_triage_report() - LLM-generated full report
5. create_triage_report() - Orchestrate the full pipeline

Output Location:
    Reports are automatically saved to: output/lab3/triage_report_<sha256>.md
    Use --no-save to skip saving, or --output to specify a custom path.

Usage (Students):
    source venv/bin/activate
    python -m student_labs.lab3.vulnerability_triage_report --help

    # Generate report for a binary (saved to output/lab3/)
    python -m student_labs.lab3.vulnerability_triage_report --sha256 <binary_sha256>

    # Generate executive summary only
    python -m student_labs.lab3.vulnerability_triage_report --sha256 <hash> --summary-only

    # Save report to custom location
    python -m student_labs.lab3.vulnerability_triage_report --sha256 <hash> --output my_report.md

    # Print to console only (no file saved)
    python -m student_labs.lab3.vulnerability_triage_report --sha256 <hash> --no-save

Usage (Instructors Only):
    # Run with reference implementation using USE_REFERENCE=1
    source venv/bin/activate
    USE_REFERENCE=1 python -m student_labs.lab3.vulnerability_triage_report --all

NOTE: The USE_REFERENCE=1 environment variable is for INSTRUCTORS ONLY.
      It requires access to the `labs/` folder which contains the reference
      implementations. Students do not have access to this folder, so using
      USE_REFERENCE=1 will result in an ImportError. Students should fill in
      the query placeholders marked with "### YOUR CODE HERE ###" instead.

Reference: docs/labs/lab3/lab_3_4_vulnerability_triage_report.md
"""

import argparse
import logging
import os
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from neo4j import Driver, GraphDatabase

from lab_common.binql import get_neo4j_credentials
from lab_common.common import get_output_dir

logger = logging.getLogger(__name__)

# Check if we should use reference implementation
_USE_REFERENCE = os.environ.get("USE_REFERENCE", "").lower() in ("1", "true", "yes")

if _USE_REFERENCE:
    # Import reference implementations to use as fallback
    from labs.lab3 import vulnerability_triage_report_reference as _ref
    logger.info("Using reference implementation for vulnerability_triage_report")


# =============================================================================
# Data Classes
# =============================================================================


@dataclass
class VulnerabilityTriageReport:
    """Complete vulnerability triage report for a binary."""

    # Binary metadata
    binary_name: str = ""
    sha256: str = ""
    analysis_timestamp: str = ""

    # Lab 3.1 findings
    input_sources: List[Any] = field(default_factory=list)
    input_source_count: int = 0

    # Lab 3.2 findings
    source_to_sink_paths: List[Any] = field(default_factory=list)
    path_count: int = 0

    # Lab 3.3 findings
    ranked_paths: List[Any] = field(default_factory=list)
    risk_distribution: Dict[str, int] = field(default_factory=dict)

    # LLM-generated content
    executive_summary: str = ""
    report_markdown: str = ""


# =============================================================================
# Helper Functions
# =============================================================================


def _get_binary_name(driver: Driver, database: str, sha256: str) -> str:
    """Get binary name from Neo4j database."""
    query = """
    MATCH (b:Binary)
    WHERE b.sha256 = $sha256 OR b.sha256 CONTAINS $sha256
    RETURN b.name AS name
    LIMIT 1
    """
    with driver.session(database=database) as session:
        result = session.run(query, sha256=sha256)
        record = result.single()
        if record:
            return record["name"]
    return sha256[:16] + "..."


def _get_all_binaries(driver: Driver, database: str) -> List[Dict[str, str]]:
    """Get all binaries from Neo4j database."""
    query = """
    MATCH (b:Binary)
    RETURN b.sha256 AS sha256, b.name AS name
    """
    with driver.session(database=database) as session:
        result = session.run(query)
        return [{"sha256": r["sha256"], "name": r["name"]} for r in result]


# =============================================================================
# Core Functions - Student Implementation
# =============================================================================


def collect_lab3_findings(
    driver: Driver,
    database: str,
    sha256: str,
) -> Dict[str, Any]:
    """
    Collect all Lab 3 findings for a binary.

    Gathers:
    - Lab 3.1: User-controlled input sources
    - Lab 3.2: Source-to-sink paths (via Lab 3.3's get_paths_for_binary)
    - Lab 3.3: Ranked path risk analysis

    Args:
        driver: Neo4j driver instance.
        database: Database name.
        sha256: Binary SHA256 hash.

    Returns:
        Dictionary with keys: input_sources, paths, risk_analyses, binary_name
    """
    if _USE_REFERENCE:
        return _ref.collect_lab3_findings(driver, database, sha256)

    ### YOUR CODE HERE ###
    # TODO: Implement this function
    # Import and call Lab 3.1, 5.2, 5.3 APIs to collect findings.
    # Return a dictionary with keys: input_sources, paths, risk_analyses, binary_name, sha256
    pass
    ### END YOUR CODE HERE ###


def format_findings_for_llm(findings: Dict[str, Any]) -> str:
    """
    Format Lab 3 findings into a structured prompt for LLM.

    Creates a text summary including:
    - Binary metadata
    - Input source summary (Lab 3.1)
    - Path summary (Lab 3.2)
    - Risk analysis summary (Lab 3.3)

    Args:
        findings: Dictionary from collect_lab3_findings().

    Returns:
        Formatted string for LLM prompt.
    """
    if _USE_REFERENCE:
        return _ref.format_findings_for_llm(findings)

    ### YOUR CODE HERE ###
    # TODO: Implement this function
    # Format the findings dictionary into a structured text for LLM prompt.
    # Return a formatted string.
    pass
    ### END YOUR CODE HERE ###


def generate_executive_summary(
    findings: Dict[str, Any],
    findings_text: str,
) -> str:
    """
    Use LLM to generate an executive summary (3-5 sentences).

    The summary should:
    1. State the overall risk level
    2. Highlight the most critical findings
    3. Recommend immediate actions if critical issues exist

    Args:
        findings: Dictionary from collect_lab3_findings().
        findings_text: Formatted findings from format_findings_for_llm().

    Returns:
        Executive summary string.
    """
    if _USE_REFERENCE:
        return _ref.generate_executive_summary(findings, findings_text)

    ### YOUR CODE HERE ###
    # TODO: Implement this function
    # Use LLM to generate an executive summary (3-5 sentences).
    # Return the summary string.
    pass
    ### END YOUR CODE HERE ###


def generate_vulnerability_triage_report(
    findings: Dict[str, Any],
    findings_text: str,
    executive_summary: str,
) -> str:
    """
    Use LLM to generate a complete vulnerability triage report in markdown.

    The report should include:
    1. Executive Summary (already generated)
    2. Risk Distribution table
    3. Detailed findings for critical/high vulnerabilities
    4. Actionable recommendations prioritized by risk

    Args:
        findings: Dictionary from collect_lab3_findings().
        findings_text: Formatted findings from format_findings_for_llm().
        executive_summary: Pre-generated executive summary.

    Returns:
        Complete markdown report.
    """
    if _USE_REFERENCE:
        return _ref.generate_vulnerability_triage_report(findings, findings_text, executive_summary)

    ### YOUR CODE HERE ###
    # TODO: Implement this function
    # Use LLM to generate a complete vulnerability triage report in markdown.
    # Return the complete markdown report string.
    pass
    ### END YOUR CODE HERE ###


def create_triage_report(
    driver: Driver,
    database: str,
    sha256: str,
    summary_only: bool = False,
) -> VulnerabilityTriageReport:
    """
    Create a complete vulnerability triage report for a binary.

    Pipeline:
    1. Collect findings from Labs 3.1, 3.2, 3.3
    2. Format findings for LLM
    3. Generate executive summary
    4. Generate full report (unless summary_only=True)
    5. Return VulnerabilityTriageReport dataclass

    Args:
        driver: Neo4j driver instance.
        database: Database name.
        sha256: Binary SHA256 hash.
        summary_only: If True, only generate executive summary.

    Returns:
        VulnerabilityTriageReport dataclass with all findings and LLM content.
    """
    if _USE_REFERENCE:
        return _ref.create_triage_report(driver, database, sha256, summary_only)

    ### YOUR CODE HERE ###
    # TODO: Implement this function
    # Follow the pipeline steps described in the docstring.
    # Return a VulnerabilityTriageReport dataclass.
    pass
    ### END YOUR CODE HERE ###


# =============================================================================
# CLI and Output Formatting
# =============================================================================


def _print_report(report: VulnerabilityTriageReport, verbose: bool = False) -> None:
    """Print the vulnerability triage report."""
    print("\n" + "=" * 70)
    print(f"VULNERABILITY TRIAGE REPORT: {report.binary_name}")
    print("=" * 70)
    print(f"SHA256: {report.sha256}")
    print(f"Analysis Time: {report.analysis_timestamp}")
    print()

    # Risk distribution
    print("Risk Distribution:")
    print(f"  ðŸ”´ Critical: {report.risk_distribution.get('critical', 0)}")
    print(f"  ðŸŸ  High:     {report.risk_distribution.get('high', 0)}")
    print(f"  ðŸŸ¡ Medium:   {report.risk_distribution.get('medium', 0)}")
    print(f"  ðŸŸ¢ Low:      {report.risk_distribution.get('low', 0)}")
    print()

    # Findings summary
    print(f"Input Sources: {report.input_source_count}")
    print(f"Source-to-Sink Paths: {report.path_count}")
    print(f"Ranked Paths: {len(report.ranked_paths)}")
    print()

    # Executive summary
    print("Executive Summary:")
    print("-" * 70)
    print(report.executive_summary)
    print("-" * 70)

    if verbose:
        print("\nFull Report:")
        print("=" * 70)
        print(report.report_markdown)
        print("=" * 70)


def main() -> int:
    """Main entry point for the CLI."""
    parser = argparse.ArgumentParser(
        description="Lab 3.4: Vulnerability Triage Report Generator"
    )
    parser.add_argument(
        "--sha256",
        type=str,
        help="SHA256 hash of the binary to analyze",
    )
    parser.add_argument(
        "--all",
        action="store_true",
        help="Generate reports for all binaries in database",
    )
    parser.add_argument(
        "--summary-only",
        action="store_true",
        help="Generate only the executive summary",
    )
    parser.add_argument(
        "--output",
        type=str,
        help="Custom output file path (default: output/lab3/triage_report_<sha256>.md)",
    )
    parser.add_argument(
        "--no-save",
        action="store_true",
        help="Do not save report to file (print to console only)",
    )
    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="Show full report in output",
    )
    args = parser.parse_args()

    # Validate arguments
    if not args.sha256 and not args.all:
        parser.error("Either --sha256 or --all is required")

    # Setup logging
    logging.basicConfig(
        level=logging.DEBUG if args.verbose else logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )

    # Connect to Neo4j
    creds = get_neo4j_credentials()
    driver = GraphDatabase.driver(
        creds["uri"],
        auth=(creds["user"], creds["password"]),
    )
    database = creds.get("database", "neo4j")

    try:
        # Get default output directory
        default_output_dir = Path(get_output_dir("lab3"))

        if args.all:
            # Generate reports for all binaries
            binaries = _get_all_binaries(driver, database)
            print(f"Generating reports for {len(binaries)} binaries...")

            for binary in binaries:
                print(f"\nProcessing: {binary['name']} ({binary['sha256'][:16]}...)")
                try:
                    report = create_triage_report(
                        driver, database, binary["sha256"], args.summary_only
                    )
                    _print_report(report, args.verbose)

                    # Always save report unless --no-save is specified
                    if not args.no_save:
                        if args.output:
                            # Custom output directory specified
                            output_dir = Path(args.output)
                            output_dir.mkdir(parents=True, exist_ok=True)
                            output_path = output_dir / f"triage_report_{binary['sha256'][:16]}.md"
                        else:
                            # Default to output/lab3/
                            output_path = default_output_dir / f"triage_report_{binary['sha256'][:16]}.md"
                        output_path.write_text(report.report_markdown)
                        print(f"Report saved to: {output_path}")

                except Exception as e:
                    logger.error(f"Error processing {binary['name']}: {e}")
                    continue

        else:
            # Generate report for single binary
            report = create_triage_report(
                driver, database, args.sha256, args.summary_only
            )
            _print_report(report, args.verbose)

            # Always save report unless --no-save is specified
            if not args.no_save:
                if args.output:
                    # Custom output path specified
                    output_path = Path(args.output)
                    output_path.parent.mkdir(parents=True, exist_ok=True)
                else:
                    # Default to output/lab3/
                    output_path = default_output_dir / f"triage_report_{args.sha256[:16]}.md"
                output_path.write_text(report.report_markdown)
                print(f"\nReport saved to: {output_path}")

        return 0

    except Exception as e:
        logger.error(f"Error: {e}")
        return 1

    finally:
        driver.close()


if __name__ == "__main__":
    module_name = Path(__file__).stem
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )
    logger = logging.getLogger(module_name)
    exit(main())
