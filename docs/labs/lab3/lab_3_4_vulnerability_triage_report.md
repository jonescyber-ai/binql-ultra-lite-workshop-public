# ğŸ”¹ Lab 3.4 â€” Vulnerability Triage Report: LLM-Powered Synthesis of Lab 3 Findings

> âœï¸ **This is an implementation lab.** You will write Python code in `student_labs/lab3/vulnerability_triage_report.py` to complete this lab.
>
> ğŸ“ **Student File:** `student_labs/lab3/vulnerability_triage_report.py`

**Lab 3.4 is the capstone of Lab 3.** It uses LLM to synthesize findings from Labs 3.1â€“3.3 into comprehensive, prioritized vulnerability triage reports with executive summaries, risk assessments, and actionable recommendations.

---

## Overview

- **Goal:** Use LLM to synthesize findings from Labs 3.1â€“3.3 into comprehensive vulnerability triage reports
  > ğŸ’° **Disclaimer:** This lab relies heavily on LLM API calls which incur costs. You are responsible for these costs. By using the materials in this workshop, you agree to the terms described in the [LLM Token Usage Disclaimer](../../token_usage_disclaimer.md).
- **Inputs:** 
  - Lab 3.1: User-controlled input sources (`UserInputSource` objects)
  - Lab 3.2: Source-to-sink paths (`SourceToSinkPath` objects)
  - Lab 3.3: Ranked path risk analysis (`PathRiskAnalysis` objects)
- **Outputs:** LLM-generated markdown report with executive summary, risk distribution, prioritized findings, and recommendations

### The Big Picture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LAB 3.4: VULNERABILITY TRIAGE REPORT                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  LAB 3.1             LAB 3.2             LAB 3.3             LAB 3.4        â”‚
â”‚  Input Sources       Source-to-Sink      Path Risk           LLM Report     â”‚
â”‚                      Paths               Analysis                           â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ recv()      â”‚    â”‚ recv() â†’    â”‚    â”‚ Score: 87   â”‚    â”‚ Executive  â”‚    â”‚
â”‚  â”‚ fread()     â”‚â”€â”€â”€â–¶â”‚ strcpy()    â”‚â”€â”€â”€â–¶â”‚ CRITICAL    â”‚â”€â”€â”€â–¶â”‚ Summary    â”‚    â”‚
â”‚  â”‚ getenv()    â”‚    â”‚             â”‚    â”‚             â”‚    â”‚            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ Findings   â”‚    â”‚
â”‚                                                           â”‚            â”‚    â”‚
â”‚  "Where does        "Can input         "Which paths       â”‚ Actions    â”‚    â”‚
â”‚   input enter?"      reach sinks?"      are highest risk?"â”‚            â”‚    â”‚
â”‚                                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â”‚  KEY INSIGHT: Lab 3.4 synthesizes ALL Lab 3 findings into                   â”‚
â”‚  a human-readable, actionable vulnerability triage report.                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why This Matters: The Capstone Pattern

**The pattern:** Graph-based analysis produces structured data â†’ LLM synthesizes into human-readable reports. This is a foundational technique you can apply to any domain where structured findings need to be communicated clearly.

---

## ğŸ¯ What You Need To Do

### Step 1: Open the Student Module

Open the vulnerability triage report module in your editor:

```bash
# View the module
cat student_labs/lab3/vulnerability_triage_report.py
```

The module provides:
- `VulnerabilityTriageReport` - Dataclass for the complete report (already implemented)
- Integration with Labs 3.1, 3.2, and 3.3 via imports
- LLM client from `lab_common.llm.client`
- 5 functions with `### YOUR CODE HERE ###` placeholders for you to fill in

### Step 2: Implement the Required Functions

You need to implement these functions:

**Data Collection Functions:**
1. **`collect_lab3_findings()`** â€” Gather all findings from Labs 3.1, 3.2, and 3.3 for a binary
2. **`format_findings_for_llm()`** â€” Format the collected findings into a structured prompt for the LLM

**LLM Report Generation Functions:**
3. **`generate_executive_summary()`** â€” Use LLM to generate a concise executive summary (3-5 sentences)
4. **`generate_vulnerability_triage_report()`** â€” Use LLM to generate the complete markdown report

**Report Assembly Function:**
5. **`create_triage_report()`** â€” Orchestrate the full pipeline: collect findings â†’ format â†’ generate report

> ğŸ“– **See the "ğŸ“š Implementation Guide" section below for detailed guidance on implementing each function.**

### Step 3: Test Your Implementation

Run the module to test your implementations:

```bash
source venv/bin/activate

# Generate full vulnerability triage report for a binary
python -m student_labs.lab3.vulnerability_triage_report --sha256 9409117ee68a2d75643bb0e0a15c71ab52d4e90fa066e419b1715e029bcdc3dd

# Generate executive summary only (quick overview)
python -m student_labs.lab3.vulnerability_triage_report --sha256 9409117ee68a2d75643bb0e0a15c71ab52d4e90fa066e419b1715e029bcdc3dd --summary-only

# Save report to a file
python -m student_labs.lab3.vulnerability_triage_report --sha256 9409117ee68a2d75643bb0e0a15c71ab52d4e90fa066e419b1715e029bcdc3dd --output report.md

# Generate reports for all binaries in database
python -m student_labs.lab3.vulnerability_triage_report --all
```

### Step 4: Run the Tests

Validate your implementation with the test suite:

```bash
source venv/bin/activate
python -m student_labs.lab3.test.test_lab_3_4 -v
```

---

## ğŸ“š Implementation Guide

This section contains detailed guidance for implementing each function. **You only need to implement the code inside the `### YOUR CODE HERE ###` markers.**

> â„¹ï¸ **Already provided in the template:** Neo4j connection setup, dataclasses (`VulnerabilityTriageReport`), Lab 3.1/3.2/3.3 imports, LLM client, CLI handling, and result formatting. You do not need to implement these.

### Function 1 â€” `collect_lab3_findings()`

This function gathers all findings from Labs 3.1, 3.2, and 3.3 for a specific binary.

**What to implement:** Call the APIs from Labs 3.1, 3.2, and 3.3 to collect findings.

```python
def collect_lab3_findings(
    driver: Driver,
    database: str,
    sha256: str,
) -> Dict[str, Any]:
    """
    Collect all Lab 3 findings for a binary.
    
    Gathers:
    - Lab 3.1: User-controlled input sources
    - Lab 3.2: Source-to-sink paths (via Lab 3.3's get_paths_for_binary)
    - Lab 3.3: Ranked path risk analysis
    
    Returns:
        Dictionary with keys: input_sources, paths, risk_analyses, binary_name
    """
    ### YOUR CODE HERE ###
    # Import Lab 3.1 API
    from student_labs.lab3.user_input_detection import (
        get_user_input_sources_for_binary,
    )
    
    # Import Lab 3.3 API (which internally uses Lab 3.2)
    from student_labs.lab3.complexity_analysis import (
        get_paths_for_binary,
        analyze_all_paths_for_binary,
    )
    
    # Collect Lab 3.1 findings: User input sources
    input_sources = get_user_input_sources_for_binary(driver, database, sha256)
    
    # Collect Lab 3.2 findings: Source-to-sink paths (via Lab 3.3 API)
    paths = get_paths_for_binary(driver, database, sha256)
    
    # Collect Lab 3.3 findings: Ranked risk analysis
    risk_analyses = analyze_all_paths_for_binary(driver, database, sha256)
    
    # Get binary name from database
    binary_name = _get_binary_name(driver, database, sha256)
    
    return {
        "input_sources": input_sources,
        "paths": paths,
        "risk_analyses": risk_analyses,
        "binary_name": binary_name,
        "sha256": sha256,
    }
    ### END YOUR CODE HERE ###
```

**Key elements:**
- Imports APIs from Labs 3.1 and 3.3
- Lab 3.3's `get_paths_for_binary()` internally calls Lab 3.2
- Returns a dictionary with all findings organized by lab

### Function 2 â€” `format_findings_for_llm()`

This function formats the collected findings into a structured prompt for the LLM.

**What to implement:** Create a formatted string summarizing all findings.

```python
def format_findings_for_llm(findings: Dict[str, Any]) -> str:
    """
    Format Lab 3 findings into a structured prompt for LLM.
    
    Creates a text summary including:
    - Binary metadata
    - Input source summary (Lab 3.1)
    - Path summary (Lab 3.2)
    - Risk analysis summary (Lab 3.3)
    """
    ### YOUR CODE HERE ###
    lines = []
    
    # Binary metadata
    lines.append(f"Binary: {findings['binary_name']}")
    lines.append(f"SHA256: {findings['sha256']}")
    lines.append("")
    
    # Lab 3.1: Input Sources
    input_sources = findings.get("input_sources", [])
    lines.append("## Input Sources (Lab 3.1)")
    if input_sources:
        # Group by category
        categories = {}
        for source in input_sources:
            cat = source.category if hasattr(source, 'category') else 'unknown'
            if cat not in categories:
                categories[cat] = []
            categories[cat].append(source)
        
        for cat, sources in categories.items():
            lines.append(f"- {cat}: {len(sources)} sources")
            for s in sources[:3]:  # Show first 3
                api = s.api if hasattr(s, 'api') else str(s)
                lines.append(f"  - {api}")
    else:
        lines.append("- No input sources detected")
    lines.append("")
    
    # Lab 3.2: Source-to-Sink Paths
    paths = findings.get("paths", [])
    lines.append("## Source-to-Sink Paths (Lab 3.2)")
    lines.append(f"- Total paths found: {len(paths)}")
    if paths:
        # Group by vulnerability type
        vuln_types = {}
        for p in paths:
            vt = p.vulnerability_type if hasattr(p, 'vulnerability_type') else 'unknown'
            vuln_types[vt] = vuln_types.get(vt, 0) + 1
        for vt, count in vuln_types.items():
            lines.append(f"  - {vt}: {count} paths")
    lines.append("")
    
    # Lab 3.3: Risk Analysis
    risk_analyses = findings.get("risk_analyses", [])
    lines.append("## Risk Analysis (Lab 3.3)")
    if risk_analyses:
        # Count by risk level
        risk_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0}
        for ra in risk_analyses:
            level = ra.risk_level if hasattr(ra, 'risk_level') else 'unknown'
            if level in risk_counts:
                risk_counts[level] += 1
        
        lines.append(f"- Critical: {risk_counts['critical']}")
        lines.append(f"- High: {risk_counts['high']}")
        lines.append(f"- Medium: {risk_counts['medium']}")
        lines.append(f"- Low: {risk_counts['low']}")
        lines.append("")
        
        # Top 5 findings
        lines.append("### Top Findings:")
        for i, ra in enumerate(risk_analyses[:5], 1):
            func = ra.function if hasattr(ra, 'function') else 'unknown'
            score = ra.combined_risk_score if hasattr(ra, 'combined_risk_score') else 0
            level = ra.risk_level if hasattr(ra, 'risk_level') else 'unknown'
            vtype = ra.vulnerability_type if hasattr(ra, 'vulnerability_type') else 'unknown'
            lines.append(f"{i}. {func}: {vtype} (Score: {score:.1f}, {level.upper()})")
    else:
        lines.append("- No risk analyses available")
    
    return "\n".join(lines)
    ### END YOUR CODE HERE ###
```

**Key elements:**
- Organizes findings by lab section
- Summarizes input sources by category
- Groups paths by vulnerability type
- Shows risk distribution and top findings

### Function 3 â€” `generate_executive_summary()`

This function uses LLM to generate a concise executive summary.

**What to implement:** Create a prompt and call the LLM to generate the summary.

```python
def generate_executive_summary(
    findings: Dict[str, Any],
    findings_text: str,
) -> str:
    """
    Use LLM to generate an executive summary (3-5 sentences).
    
    The summary should:
    1. State the overall risk level
    2. Highlight the most critical findings
    3. Recommend immediate actions if critical issues exist
    """
    ### YOUR CODE HERE ###
    from lab_common.llm.client import llm_completion
    
    system_prompt = """You are a senior security analyst writing an executive summary for a vulnerability triage report.

Your summary should:
1. Be concise (3-5 sentences)
2. Highlight the most critical findings
3. Provide a risk assessment (Critical/High/Medium/Low overall)
4. Recommend immediate actions if critical issues exist

Write in a professional tone suitable for security leadership."""

    user_prompt = f"""Generate an executive summary for this binary vulnerability analysis:

{findings_text}

Write a 3-5 sentence executive summary."""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]
    
    context = llm_completion(messages)
    
    return context.response.strip()
    ### END YOUR CODE HERE ###
```

**Key elements:**
- Uses `lab_common.llm.client.llm_completion()`
- System prompt defines the analyst persona and requirements
- User prompt includes the formatted findings

### Function 4 â€” `generate_vulnerability_triage_report()`

This function uses LLM to generate the complete markdown report.

**What to implement:** Create a comprehensive prompt and call the LLM.

```python
def generate_vulnerability_triage_report(
    findings: Dict[str, Any],
    findings_text: str,
    executive_summary: str,
) -> str:
    """
    Use LLM to generate a complete vulnerability triage report in markdown.
    
    The report should include:
    1. Executive Summary (already generated)
    2. Risk Distribution table
    3. Detailed findings for critical/high vulnerabilities
    4. Actionable recommendations prioritized by risk
    """
    ### YOUR CODE HERE ###
    from lab_common.llm.client import llm_completion
    
    system_prompt = """You are a security analyst generating a comprehensive vulnerability triage report.

The report should include:
1. Executive Summary (provided - include as-is)
2. Risk Distribution table (markdown table format)
3. Detailed findings for each critical/high vulnerability
4. Actionable recommendations prioritized by risk

Format the output as markdown. Use tables where appropriate.
Be specific about vulnerability types (CWE references) and remediation steps."""

    user_prompt = f"""Generate a vulnerability triage report for:

{findings_text}

Executive Summary (include this in the report):
{executive_summary}

Generate a complete triage report with:
1. The executive summary above
2. Risk distribution table
3. Detailed findings (focus on critical and high risk)
4. Prioritized recommendations

Format as markdown."""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]
    
    context = llm_completion(messages)
    
    return context.response.strip()
    ### END YOUR CODE HERE ###
```

**Key elements:**
- Includes the pre-generated executive summary
- Requests specific sections: risk distribution, findings, recommendations
- Asks for CWE references and specific remediation steps

### Function 5 â€” `create_triage_report()`

This function orchestrates the full pipeline.

**What to implement:** Call the other functions in sequence.

```python
def create_triage_report(
    driver: Driver,
    database: str,
    sha256: str,
    summary_only: bool = False,
) -> VulnerabilityTriageReport:
    """
    Create a complete vulnerability triage report for a binary.
    
    Pipeline:
    1. Collect findings from Labs 3.1, 3.2, 3.3
    2. Format findings for LLM
    3. Generate executive summary
    4. Generate full report (unless summary_only=True)
    5. Return VulnerabilityTriageReport dataclass
    """
    ### YOUR CODE HERE ###
    from datetime import datetime
    
    # Step 1: Collect findings
    findings = collect_lab3_findings(driver, database, sha256)
    
    # Step 2: Format for LLM
    findings_text = format_findings_for_llm(findings)
    
    # Step 3: Generate executive summary
    executive_summary = generate_executive_summary(findings, findings_text)
    
    # Step 4: Generate full report (unless summary_only)
    if summary_only:
        report_markdown = f"# Executive Summary\n\n{executive_summary}"
    else:
        report_markdown = generate_vulnerability_triage_report(
            findings, findings_text, executive_summary
        )
    
    # Step 5: Build risk distribution
    risk_analyses = findings.get("risk_analyses", [])
    risk_distribution = {"critical": 0, "high": 0, "medium": 0, "low": 0}
    for ra in risk_analyses:
        level = ra.risk_level if hasattr(ra, 'risk_level') else 'unknown'
        if level in risk_distribution:
            risk_distribution[level] += 1
    
    # Step 6: Create and return the report dataclass
    return VulnerabilityTriageReport(
        binary_name=findings.get("binary_name", "unknown"),
        sha256=sha256,
        analysis_timestamp=datetime.now().isoformat(),
        input_sources=findings.get("input_sources", []),
        input_source_count=len(findings.get("input_sources", [])),
        source_to_sink_paths=findings.get("paths", []),
        path_count=len(findings.get("paths", [])),
        ranked_paths=risk_analyses,
        risk_distribution=risk_distribution,
        executive_summary=executive_summary,
        report_markdown=report_markdown,
    )
    ### END YOUR CODE HERE ###
```

**Key elements:**
- Calls functions in sequence: collect â†’ format â†’ summarize â†’ report
- Supports `summary_only` mode for quick overview
- Returns a complete `VulnerabilityTriageReport` dataclass

---

## âœ… Success Criteria

Your implementation is complete when:

- [ ] All 5 functions are implemented in `student_labs/lab3/vulnerability_triage_report.py`
- [ ] The CLI runs without errors:
  ```bash
  source venv/bin/activate
  python -m student_labs.lab3.vulnerability_triage_report --sha256 9409117ee68a2d75643bb0e0a15c71ab52d4e90fa066e419b1715e029bcdc3dd
  ```
- [ ] Reports include executive summary, risk distribution, findings, and recommendations
- [ ] All tests pass:
  ```bash
  source venv/bin/activate
  python -m student_labs.lab3.test.test_lab_3_4
  ```

---

## Summary

In this lab, you implemented:

| Component | What It Does |
|-----------|--------------|
| **Data Collection** | Gather findings from Labs 3.1, 3.2, and 3.3 |
| **LLM Formatting** | Structure findings into effective prompts |
| **Executive Summary** | LLM-generated 3-5 sentence overview |
| **Full Report** | Comprehensive markdown with findings and recommendations |
| **Pipeline Orchestration** | End-to-end report generation |

**Key Insight:** Lab 3.4 demonstrates the **LLM synthesis pattern** â€” using LLM to transform structured analysis data into human-readable, actionable reports. This same pattern applies wherever graph-based findings need to be communicated to stakeholders.

> ğŸ’¡ **Why we use explicit Cypher here:** While NL2GQL (from Lab 2) is great for exploratory discovery, we use explicit, pre-defined Cypher queries for the vulnerability analysis pipeline in Lab 3. When you have a specific objective that you need to run repeatably, specifying the query provides the **consistent, deterministic, and reliable outcomes** required for a production-grade analysis workflow.

---

## ğŸ§­ Workshop Wrap-Up

Lab 3.4 is the **final lab** in this workshop. Together, Labs 1â€“3 demonstrate the full arc of graph-grounded binary analysis:

| Lab | What You Learned |
|-----|-----------------|
| **Lab 1** | Load binaries into a graph and explore program structure with Cypher |
| **Lab 2** | Build NL2GQL â€” ask questions in English, get graph-backed answers |
| **Lab 3** | Use the graph for vulnerability analysis â€” from input detection to LLM-powered triage reports |

The techniques you've practiced â€” CFG reachability, cross-binary queries, LLM synthesis â€” are building blocks that extend naturally to malware analysis, CVE triage, firmware ecosystems, and agentic workflows. The richer **binql-lite** (used in our 4-day courses) and the upcoming **full open-source binql** build on exactly these foundations.

> ğŸ’¡ **Key Principle:** The graph is the interface between analyst intent and automated reasoning â€” *structure first, then automate*.

---

## ğŸ“š Additional Reading

### The Complete Lab 3 Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  COMPLETE VULNERABILITY ANALYSIS PIPELINE                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  LAB 3.1             LAB 3.2             LAB 3.3             LAB 3.4        â”‚
â”‚  Input Sources       Source-to-Sink      Path Risk           LLM Report     â”‚
â”‚                      Paths               Analysis                           â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ recv()      â”‚    â”‚ recv() â†’    â”‚    â”‚ Score: 87   â”‚    â”‚ Executive  â”‚    â”‚
â”‚  â”‚ fread()     â”‚â”€â”€â”€â–¶â”‚ strcpy()    â”‚â”€â”€â”€â–¶â”‚ CRITICAL    â”‚â”€â”€â”€â–¶â”‚ Summary    â”‚    â”‚
â”‚  â”‚ getenv()    â”‚    â”‚             â”‚    â”‚             â”‚    â”‚            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ Findings   â”‚    â”‚
â”‚                                                           â”‚            â”‚    â”‚
â”‚  "Where does        "Can input         "Which paths       â”‚ Actions    â”‚    â”‚
â”‚   input enter?"      reach sinks?"      are highest risk?"â”‚            â”‚    â”‚
â”‚                                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### LLM Prompt Engineering Tips

| Tip | Description |
|-----|-------------|
| **Be specific** | Tell the LLM exactly what sections to include |
| **Provide context** | Include all relevant data in the prompt |
| **Set the persona** | "You are a senior security analyst..." |
| **Request format** | "Format as markdown with tables" |
| **Include examples** | Show the expected output structure |

### CLI Reference

```bash
source venv/bin/activate

# Generate full report for a binary
python -m student_labs.lab3.vulnerability_triage_report --sha256 <binary_sha256>

# Generate executive summary only
python -m student_labs.lab3.vulnerability_triage_report --sha256 <hash> --summary-only

# Save report to file
python -m student_labs.lab3.vulnerability_triage_report --sha256 <hash> --output report.md

# Generate reports for all binaries
python -m student_labs.lab3.vulnerability_triage_report --all

# Verbose output
python -m student_labs.lab3.vulnerability_triage_report --sha256 <hash> --verbose
```

| Flag | Description |
|------|-------------|
| `--sha256 <hash>` | Generate report for a specific binary |
| `--all` | Generate reports for all binaries in database |
| `--summary-only` | Generate only the executive summary |
| `--output <file>` | Save report to a file |
| `--verbose` | Show detailed progress |

### The LLM Synthesis Pattern

Lab 3.4 establishes the **LLM synthesis pattern**: collect structured findings from graph queries â†’ format them into an effective prompt â†’ use an LLM to generate a human-readable report. This pattern is broadly applicable â€” swap in different graph queries and domain context, and the same pipeline produces malware summaries, CVE triage reports, or automated investigation write-ups.
